{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用定位器结果的分类器\n",
    "这里是localizer方法下的分类器。\n",
    "输入是localizer截出来的鱼的子图（Nx3x100x100），理想情况就是刚刚好的一条鱼。输出是分类器分好的各个类的分数（Nx8）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "np.random.seed(2017)\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D\n",
    "from keras.optimizers import SGD, Adagrad\n",
    "from keras.utils import np_utils\n",
    "from keras.constraints import maxnorm\n",
    "from sklearn.metrics import log_loss\n",
    "from keras import __version__ as keras_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_path = '../deep-learning-models/vgg16_weights.h5'\n",
    "top_model_weights_path = 'classification/class_bottleneck_fc_model.h5'\n",
    "# dimensions of our images.0\n",
    "img_width, img_height = 100, 100\n",
    "nb_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_from_file(filename):\n",
    "\timport numpy as np\n",
    "\treturn np.load( filename + '.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_target = load_from_file('classification/train_target_100')\n",
    "train_data = load_from_file('classification/train_data_100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3764, 3, 100, 100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_val():\n",
    "    train_target = load_from_file('classification/train_target_100')\n",
    "    train_data = load_from_file('classification/train_data_100')\n",
    "    return train_data, train_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1\n",
    "Fine Tune第一步是使用已经训练好的vgg16模型提取features.即将vgg16最后一个convBlock的输出作为features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_bottleneck_features():\n",
    "    # build the VGG16 network\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1, 1), input_shape=(3, img_width, img_height)))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1', dim_ordering='th'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2', dim_ordering='th'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1', dim_ordering='th'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2', dim_ordering='th'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1', dim_ordering='th'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2', dim_ordering='th'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3', dim_ordering='th'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1', dim_ordering='th'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2', dim_ordering='th'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3', dim_ordering='th'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1', dim_ordering='th'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2', dim_ordering='th'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3', dim_ordering='th'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    # load the weights of the VGG16 networks\n",
    "    # (trained on ImageNet, won the ILSVRC competition in 2014)\n",
    "    # note: when there is a complete match between your model definition\n",
    "    # and your weight savefile, you can simply call model.load_weights(filename)\n",
    "    assert os.path.exists(weights_path), 'Model weights not found (see \"weights_path\" variable in script).'\n",
    "    f = h5py.File(weights_path)\n",
    "    for k in range(f.attrs['nb_layers']):\n",
    "        if k >= len(model.layers):\n",
    "            # we don't look at the last (fully-connected) layers in the savefile\n",
    "            break\n",
    "        g = f['layer_{}'.format(k)]\n",
    "        weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
    "        model.layers[k].set_weights(weights)\n",
    "    f.close()\n",
    "    print('Model loaded.')\n",
    "    # data generator:\n",
    "    X, Y = get_train_val()\n",
    "    # train:\n",
    "    bottleneck_features_train = model.predict(X[330:], batch_size=32, verbose=0)\n",
    "    np.save(open('classification/local_bottleneck_features_train.npy', 'w'), bottleneck_features_train)\n",
    "    # validation:\n",
    "    bottleneck_features_val = model.predict(X[:330], batch_size=32, verbose=0)\n",
    "    np.save(open('classification/local_bottleneck_features_val.npy', 'w'), bottleneck_features_val)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "save_bottleneck_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "Fine Tune第二步是使用第一步提取的特征训练一个自定义的适用于自己要解决的问题的head.这里是训练分类器，所以是classification head。\n",
    "将训练好的weights保存作为正式进行训练时的初始值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_top_model():\n",
    "    from keras.callbacks import EarlyStopping\n",
    "    train_target = load_from_file('classification/train_target_100')\n",
    "    \n",
    "    train_data = np.load(open('classification/local_bottleneck_features_train.npy'))\n",
    "    train_labels = train_target[330:]\n",
    "\n",
    "    validation_data = np.load(open('classification/local_bottleneck_features_val.npy'))\n",
    "    validation_labels = train_target[:330]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(96, activation='relu',init='he_uniform'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(24, activation='relu',init='he_uniform'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "    sgd = SGD(lr=1e-2, decay=1e-4, momentum=0.89, nesterov=False)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=3, verbose=0),\n",
    "        ]\n",
    "    model.fit(train_data, train_labels,\n",
    "              nb_epoch=nb_epoch, batch_size=32, shuffle=True, verbose=2, \n",
    "              validation_data=(validation_data, validation_labels), callbacks = callbacks)\n",
    "    model.save_weights(top_model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3434 samples, validate on 330 samples\n",
      "Epoch 1/10\n",
      "2s - loss: 1.7856 - acc: 0.3888 - val_loss: 0.5598 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      "1s - loss: 1.5010 - acc: 0.4694 - val_loss: 0.9134 - val_acc: 0.9879\n",
      "Epoch 3/10\n",
      "1s - loss: 1.4476 - acc: 0.4802 - val_loss: 0.8834 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      "1s - loss: 1.4193 - acc: 0.4988 - val_loss: 0.6802 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      "1s - loss: 1.4016 - acc: 0.4965 - val_loss: 0.6192 - val_acc: 0.9939\n"
     ]
    }
   ],
   "source": [
    "train_top_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3\n",
    "Fine Tune第三步是利用第二步训练好的头部weights和vgg16模型本身的weights在自己问题上的数据集进行训练。\n",
    "这里数据规模中等的情况下freeze掉前四层convblock，对最后一个convblock和头部进行权值更新。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build the VGG16 network\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1, 1), input_shape=(3, img_width, img_height)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "assert os.path.exists(weights_path), 'Model weights not found (see \"weights_path\" variable in script).'\n",
    "f = h5py.File(weights_path)\n",
    "for k in range(f.attrs['nb_layers']):\n",
    "    if k >= len(model.layers):\n",
    "        # we don't look at the last (fully-connected) layers in the savefile\n",
    "        break\n",
    "    g = f['layer_{}'.format(k)]\n",
    "    weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
    "    model.layers[k].set_weights(weights)\n",
    "f.close()\n",
    "print('Model loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "top_model.add(Dense(96, activation='relu',init='he_uniform'))\n",
    "top_model.add(Dropout(0.4))\n",
    "top_model.add(Dense(24, activation='relu',init='he_uniform'))\n",
    "top_model.add(Dropout(0.2))\n",
    "top_model.add(Dense(8, activation='softmax'))\n",
    "# note that it is necessary to start with a fully-trained\n",
    "# classifier, including the top classifier,\n",
    "# in order to successfully do fine-tuning\n",
    "top_model.load_weights(top_model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add the model on top of the convolutional base\n",
    "model.add(top_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the first 25 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in model.layers[:25]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "sgd = SGD(lr=1e-4, decay=1e-6, momentum=0.9, nesterov=False)\n",
    "\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3434 samples, validate on 330 samples\n",
      "Epoch 1/10\n",
      "1592s - loss: 1.3282 - acc: 0.5111 - val_loss: 0.5808 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      "1577s - loss: 1.3252 - acc: 0.5116 - val_loss: 0.5738 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      "2952s - loss: 1.3006 - acc: 0.5122 - val_loss: 0.5601 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      "2827s - loss: 1.3066 - acc: 0.5099 - val_loss: 0.5328 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      "2872s - loss: 1.2890 - acc: 0.5140 - val_loss: 0.5052 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "2817s - loss: 1.2758 - acc: 0.5149 - val_loss: 0.5051 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "2747s - loss: 1.2760 - acc: 0.5154 - val_loss: 0.5022 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "2940s - loss: 1.2667 - acc: 0.5151 - val_loss: 0.4949 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "3119s - loss: 1.2708 - acc: 0.5154 - val_loss: 0.4313 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "2930s - loss: 1.2527 - acc: 0.5178 - val_loss: 0.4261 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# fine tune:\n",
    "X, Y = get_train_val()\n",
    "train_data = X[330:]\n",
    "train_labels = Y[330:]\n",
    "validation_data = X[:330]\n",
    "validation_labels = Y[:330]\n",
    "callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=3, verbose=0)\n",
    "        ]\n",
    "model.fit(train_data, train_labels,\n",
    "              nb_epoch=nb_epoch, batch_size=32, shuffle=True, verbose=2,\n",
    "              validation_data=(validation_data, validation_labels), callbacks=callbacks)\n",
    "    \n",
    "model.save_weights('classification/local-fine-tune-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n",
      "Train on 3434 samples, validate on 330 samples\n",
      "Epoch 1/10\n",
      "3001s - loss: 1.3073 - acc: 0.5111 - val_loss: 0.3298 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      "2833s - loss: 1.2361 - acc: 0.5527 - val_loss: 0.5236 - val_acc: 0.9394\n",
      "Epoch 3/10\n",
      "2777s - loss: 1.1992 - acc: 0.5789 - val_loss: 0.2080 - val_acc: 0.9788\n",
      "Epoch 4/10\n",
      "2809s - loss: 1.1292 - acc: 0.6095 - val_loss: 0.3828 - val_acc: 0.9606\n",
      "Epoch 5/10\n",
      "2743s - loss: 1.0011 - acc: 0.6471 - val_loss: 0.3565 - val_acc: 0.9030\n",
      "Epoch 6/10\n",
      "2752s - loss: 0.9260 - acc: 0.6744 - val_loss: 0.0891 - val_acc: 0.9848\n",
      "Epoch 7/10\n",
      "2779s - loss: 0.8419 - acc: 0.7053 - val_loss: 0.1874 - val_acc: 0.9606\n",
      "Epoch 8/10\n",
      "2755s - loss: 0.7352 - acc: 0.7242 - val_loss: 0.1595 - val_acc: 0.9576\n",
      "Epoch 9/10\n",
      "2753s - loss: 0.7493 - acc: 0.7289 - val_loss: 0.3716 - val_acc: 0.9182\n",
      "Epoch 10/10\n",
      "2749s - loss: 0.6129 - acc: 0.7662 - val_loss: 0.2646 - val_acc: 0.9364\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('classification/local-fine-tune-model.h5')\n",
    "print 'model loaded'\n",
    "sgd = SGD(lr=1e-3, decay=1e-5, momentum=0.9, nesterov=False)\n",
    "\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=3, verbose=0)\n",
    "        ]\n",
    "\n",
    "model.fit(train_data, train_labels,\n",
    "              nb_epoch=nb_epoch, batch_size=32, shuffle=True, verbose=2,\n",
    "              validation_data=(validation_data, validation_labels), callbacks=callbacks)\n",
    "    \n",
    "model.save_weights('classification/local-fine-tune-model_second10epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3434 samples, validate on 330 samples\n",
      "Epoch 1/10\n",
      "2895s - loss: 0.5864 - acc: 0.7854 - val_loss: 0.2466 - val_acc: 0.9424\n",
      "Epoch 2/10\n",
      "2975s - loss: 0.4885 - acc: 0.8241 - val_loss: 0.2202 - val_acc: 0.9576\n",
      "Epoch 3/10\n",
      "3117s - loss: 0.4089 - acc: 0.8559 - val_loss: 0.1040 - val_acc: 0.9909\n",
      "Epoch 4/10\n",
      "2836s - loss: 0.3603 - acc: 0.8727 - val_loss: 0.6311 - val_acc: 0.7818\n",
      "Epoch 5/10\n",
      "2866s - loss: 0.3236 - acc: 0.8925 - val_loss: 0.3231 - val_acc: 0.8939\n",
      "Epoch 6/10\n",
      "2897s - loss: 0.2735 - acc: 0.9077 - val_loss: 0.1101 - val_acc: 0.9758\n",
      "Epoch 7/10\n",
      "2756s - loss: 0.2693 - acc: 0.9086 - val_loss: 0.3054 - val_acc: 0.9273\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_data, train_labels,\n",
    "              nb_epoch=nb_epoch, batch_size=32, shuffle=True, verbose=2,\n",
    "              validation_data=(validation_data, validation_labels), callbacks=callbacks)\n",
    "    \n",
    "model.save_weights('classification/local-fine-tune-model_third10epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fine tune:\n",
    "X, Y = get_train_val()\n",
    "train_data = X[330:]\n",
    "train_labels = Y[330:]\n",
    "validation_data = X[:330]\n",
    "validation_labels = Y[:330]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.33333334,  0.31764707,  0.3137255 , ...,  0.18039216,\n",
       "           0.19215687,  0.1882353 ],\n",
       "         [ 0.32941177,  0.32941177,  0.32941177, ...,  0.1882353 ,\n",
       "           0.18039216,  0.18039216],\n",
       "         [ 0.32156864,  0.32549021,  0.33333334, ...,  0.27843139,\n",
       "           0.2       ,  0.17647059],\n",
       "         ..., \n",
       "         [ 0.37254903,  0.36078432,  0.35686275, ...,  0.67058825,\n",
       "           0.25882354,  0.18431373],\n",
       "         [ 0.3764706 ,  0.36862746,  0.36470589, ...,  0.69411767,\n",
       "           0.27843139,  0.19215687],\n",
       "         [ 0.38431373,  0.3764706 ,  0.37254903, ...,  0.65882355,\n",
       "           0.34901962,  0.15686275]],\n",
       "\n",
       "        [[ 0.33725491,  0.33725491,  0.32549021, ...,  0.17254902,\n",
       "           0.18431373,  0.18039216],\n",
       "         [ 0.34117648,  0.34509805,  0.34509805, ...,  0.18039216,\n",
       "           0.17254902,  0.17254902],\n",
       "         [ 0.34117648,  0.34901962,  0.35294119, ...,  0.27058825,\n",
       "           0.19215687,  0.16862746],\n",
       "         ..., \n",
       "         [ 0.37254903,  0.36078432,  0.35686275, ...,  0.66274512,\n",
       "           0.25490198,  0.1882353 ],\n",
       "         [ 0.3764706 ,  0.36862746,  0.36470589, ...,  0.68235296,\n",
       "           0.27450982,  0.19607843],\n",
       "         [ 0.38431373,  0.3764706 ,  0.37254903, ...,  0.64705884,\n",
       "           0.34509805,  0.16078432]],\n",
       "\n",
       "        [[ 0.29411766,  0.29411766,  0.29019609, ...,  0.19607843,\n",
       "           0.20784314,  0.20392157],\n",
       "         [ 0.29803923,  0.3019608 ,  0.30980393, ...,  0.20392157,\n",
       "           0.19607843,  0.19607843],\n",
       "         [ 0.29803923,  0.3137255 ,  0.32941177, ...,  0.29019609,\n",
       "           0.21568628,  0.19215687],\n",
       "         ..., \n",
       "         [ 0.37254903,  0.36078432,  0.35686275, ...,  0.66666669,\n",
       "           0.26274511,  0.20392157],\n",
       "         [ 0.3764706 ,  0.36862746,  0.36470589, ...,  0.68627453,\n",
       "           0.28235295,  0.21176471],\n",
       "         [ 0.38431373,  0.3764706 ,  0.37254903, ...,  0.65098041,\n",
       "           0.35294119,  0.17647059]]],\n",
       "\n",
       "\n",
       "       [[[ 0.33333334,  0.32549021,  0.32941177, ...,  0.38039216,\n",
       "           0.38039216,  0.37254903],\n",
       "         [ 0.33333334,  0.32549021,  0.32549021, ...,  0.38431373,\n",
       "           0.38039216,  0.38039216],\n",
       "         [ 0.33333334,  0.32941177,  0.32941177, ...,  0.38039216,\n",
       "           0.38039216,  0.3764706 ],\n",
       "         ..., \n",
       "         [ 0.50980395,  0.50588238,  0.50196081, ...,  0.38431373,\n",
       "           0.38431373,  0.36862746],\n",
       "         [ 0.52156866,  0.50980395,  0.51372552, ...,  0.38039216,\n",
       "           0.38039216,  0.37254903],\n",
       "         [ 0.51372552,  0.51764709,  0.51764709, ...,  0.38431373,\n",
       "           0.3882353 ,  0.38039216]],\n",
       "\n",
       "        [[ 0.18431373,  0.18431373,  0.1882353 , ...,  0.3137255 ,\n",
       "           0.3137255 ,  0.30980393],\n",
       "         [ 0.18431373,  0.18431373,  0.18431373, ...,  0.31764707,\n",
       "           0.31764707,  0.3137255 ],\n",
       "         [ 0.18431373,  0.18431373,  0.19215687, ...,  0.3137255 ,\n",
       "           0.30980393,  0.30980393],\n",
       "         ..., \n",
       "         [ 0.53333336,  0.52156866,  0.51764709, ...,  0.31764707,\n",
       "           0.31764707,  0.30588236],\n",
       "         [ 0.54509807,  0.53333336,  0.52156866, ...,  0.30980393,\n",
       "           0.3137255 ,  0.3019608 ],\n",
       "         [ 0.53333336,  0.53333336,  0.52549022, ...,  0.3137255 ,\n",
       "           0.31764707,  0.30588236]],\n",
       "\n",
       "        [[ 0.16862746,  0.16078432,  0.16470589, ...,  0.27843139,\n",
       "           0.27843139,  0.27058825],\n",
       "         [ 0.16470589,  0.16078432,  0.16078432, ...,  0.28235295,\n",
       "           0.28235295,  0.27843139],\n",
       "         [ 0.16470589,  0.16470589,  0.16862746, ...,  0.27843139,\n",
       "           0.27843139,  0.27450982],\n",
       "         ..., \n",
       "         [ 0.5529412 ,  0.54509807,  0.53725493, ...,  0.28235295,\n",
       "           0.28235295,  0.27058825],\n",
       "         [ 0.57254905,  0.56078434,  0.56078434, ...,  0.26666668,\n",
       "           0.27058825,  0.25882354],\n",
       "         [ 0.57254905,  0.57254905,  0.56470591, ...,  0.27058825,\n",
       "           0.27450982,  0.25882354]]],\n",
       "\n",
       "\n",
       "       [[[ 0.43529412,  0.4509804 ,  0.44313726, ...,  0.10196079,\n",
       "           0.10196079,  0.10196079],\n",
       "         [ 0.43921569,  0.44705883,  0.44705883, ...,  0.10196079,\n",
       "           0.10196079,  0.10196079],\n",
       "         [ 0.43529412,  0.44313726,  0.44313726, ...,  0.10196079,\n",
       "           0.10196079,  0.09803922],\n",
       "         ..., \n",
       "         [ 0.54901963,  0.54901963,  0.54901963, ...,  0.27058825,\n",
       "           0.29019609,  0.28627452],\n",
       "         [ 0.54901963,  0.54901963,  0.54901963, ...,  0.27058825,\n",
       "           0.28627452,  0.28627452],\n",
       "         [ 0.54901963,  0.54901963,  0.54901963, ...,  0.27058825,\n",
       "           0.29019609,  0.28627452]],\n",
       "\n",
       "        [[ 0.48627451,  0.50196081,  0.49411765, ...,  0.13725491,\n",
       "           0.13725491,  0.13725491],\n",
       "         [ 0.48627451,  0.49803922,  0.49803922, ...,  0.13725491,\n",
       "           0.13725491,  0.13725491],\n",
       "         [ 0.48627451,  0.49411765,  0.49411765, ...,  0.13725491,\n",
       "           0.13725491,  0.13333334],\n",
       "         ..., \n",
       "         [ 0.55686277,  0.56078434,  0.56078434, ...,  0.3137255 ,\n",
       "           0.32156864,  0.3137255 ],\n",
       "         [ 0.55686277,  0.55686277,  0.55686277, ...,  0.3137255 ,\n",
       "           0.32156864,  0.3137255 ],\n",
       "         [ 0.55686277,  0.55686277,  0.55686277, ...,  0.3137255 ,\n",
       "           0.32549021,  0.3137255 ]],\n",
       "\n",
       "        [[ 0.47843137,  0.49411765,  0.48627451, ...,  0.17254902,\n",
       "           0.17647059,  0.17647059],\n",
       "         [ 0.48235294,  0.49019608,  0.49019608, ...,  0.17647059,\n",
       "           0.17647059,  0.17647059],\n",
       "         [ 0.47843137,  0.48627451,  0.48627451, ...,  0.17647059,\n",
       "           0.17647059,  0.17254902],\n",
       "         ..., \n",
       "         [ 0.5529412 ,  0.5529412 ,  0.5529412 , ...,  0.34901962,\n",
       "           0.38431373,  0.39215687],\n",
       "         [ 0.55686277,  0.55686277,  0.55686277, ...,  0.34901962,\n",
       "           0.3764706 ,  0.39215687],\n",
       "         [ 0.55686277,  0.55686277,  0.55686277, ...,  0.34509805,\n",
       "           0.3764706 ,  0.39215687]]],\n",
       "\n",
       "\n",
       "       ..., \n",
       "       [[[ 0.8509804 ,  0.90588236,  0.82745099, ...,  0.41960785,\n",
       "           0.29803923,  0.28235295],\n",
       "         [ 0.84705883,  0.82745099,  0.82745099, ...,  0.37254903,\n",
       "           0.32156864,  0.18431373],\n",
       "         [ 0.81176472,  0.83529413,  0.83529413, ...,  0.34901962,\n",
       "           0.32549021,  0.12941177],\n",
       "         ..., \n",
       "         [ 0.37254903,  0.3764706 ,  0.39215687, ...,  0.35294119,\n",
       "           0.35686275,  0.38039216],\n",
       "         [ 0.36470589,  0.3764706 ,  0.3764706 , ...,  0.34117648,\n",
       "           0.34509805,  0.38039216],\n",
       "         [ 0.36078432,  0.38039216,  0.36470589, ...,  0.32941177,\n",
       "           0.34117648,  0.38039216]],\n",
       "\n",
       "        [[ 0.86274511,  0.9137255 ,  0.83137256, ...,  0.56470591,\n",
       "           0.43529412,  0.40000001],\n",
       "         [ 0.85882354,  0.83137256,  0.83137256, ...,  0.51764709,\n",
       "           0.45490196,  0.3019608 ],\n",
       "         [ 0.82352942,  0.8392157 ,  0.8392157 , ...,  0.50588238,\n",
       "           0.4627451 ,  0.24705882],\n",
       "         ..., \n",
       "         [ 0.37254903,  0.3764706 ,  0.39215687, ...,  0.46666667,\n",
       "           0.47058824,  0.49411765],\n",
       "         [ 0.36470589,  0.3764706 ,  0.3764706 , ...,  0.45490196,\n",
       "           0.45882353,  0.49411765],\n",
       "         [ 0.36078432,  0.38039216,  0.36470589, ...,  0.44313726,\n",
       "           0.45490196,  0.49411765]],\n",
       "\n",
       "        [[ 0.89411765,  0.95294118,  0.87058824, ...,  0.66666669,\n",
       "           0.53725493,  0.50588238],\n",
       "         [ 0.89019608,  0.87058824,  0.87058824, ...,  0.61960787,\n",
       "           0.55686277,  0.40784314],\n",
       "         [ 0.85490197,  0.87843138,  0.87843138, ...,  0.60392159,\n",
       "           0.56470591,  0.35294119],\n",
       "         ..., \n",
       "         [ 0.37254903,  0.3764706 ,  0.39215687, ...,  0.58823532,\n",
       "           0.59215689,  0.6156863 ],\n",
       "         [ 0.36470589,  0.3764706 ,  0.3764706 , ...,  0.57647061,\n",
       "           0.58039218,  0.6156863 ],\n",
       "         [ 0.36078432,  0.38039216,  0.36470589, ...,  0.56470591,\n",
       "           0.57647061,  0.6156863 ]]],\n",
       "\n",
       "\n",
       "       [[[ 0.79215688,  0.92941177,  0.78431374, ...,  0.56470591,\n",
       "           0.47843137,  0.48627451],\n",
       "         [ 0.78823531,  0.85490197,  0.9137255 , ...,  0.58823532,\n",
       "           0.44705883,  0.4627451 ],\n",
       "         [ 0.79607844,  0.80000001,  0.96078432, ...,  0.59607846,\n",
       "           0.43921569,  0.4509804 ],\n",
       "         ..., \n",
       "         [ 0.72549021,  0.71764708,  0.71764708, ...,  0.75294119,\n",
       "           0.76078433,  0.77254903],\n",
       "         [ 0.72156864,  0.71764708,  0.71764708, ...,  0.78823531,\n",
       "           0.81960785,  0.85490197],\n",
       "         [ 0.72156864,  0.72156864,  0.71764708, ...,  0.8392157 ,\n",
       "           0.79215688,  0.68235296]],\n",
       "\n",
       "        [[ 0.75294119,  0.94901961,  0.83137256, ...,  0.60000002,\n",
       "           0.52941179,  0.53333336],\n",
       "         [ 0.74901962,  0.87058824,  0.95686275, ...,  0.61960787,\n",
       "           0.49803922,  0.50980395],\n",
       "         [ 0.75686276,  0.80784315,  0.99607843, ...,  0.63137257,\n",
       "           0.48627451,  0.49803922],\n",
       "         ..., \n",
       "         [ 0.67058825,  0.66666669,  0.67058825, ...,  0.78431374,\n",
       "           0.79215688,  0.80392158],\n",
       "         [ 0.66666669,  0.66666669,  0.67058825, ...,  0.81176472,\n",
       "           0.84705883,  0.87843138],\n",
       "         [ 0.66666669,  0.67058825,  0.67058825, ...,  0.85882354,\n",
       "           0.81176472,  0.7019608 ]],\n",
       "\n",
       "        [[ 0.78823531,  0.96078432,  0.83137256, ...,  0.65490198,\n",
       "           0.57647061,  0.57254905],\n",
       "         [ 0.78431374,  0.88235295,  0.95686275, ...,  0.67450982,\n",
       "           0.53725493,  0.54901963],\n",
       "         [ 0.78431374,  0.82352942,  0.99607843, ...,  0.68235296,\n",
       "           0.52549022,  0.53725493],\n",
       "         ..., \n",
       "         [ 0.67450982,  0.65882355,  0.66274512, ...,  0.78431374,\n",
       "           0.79215688,  0.80392158],\n",
       "         [ 0.67058825,  0.65882355,  0.66274512, ...,  0.81568629,\n",
       "           0.8509804 ,  0.88235295],\n",
       "         [ 0.67058825,  0.66274512,  0.66274512, ...,  0.86274511,\n",
       "           0.81568629,  0.70588237]]],\n",
       "\n",
       "\n",
       "       [[[ 0.49411765,  0.47843137,  0.4509804 , ...,  0.98039216,\n",
       "           0.97254902,  0.99215686],\n",
       "         [ 0.47450981,  0.46666667,  0.44313726, ...,  0.97647059,\n",
       "           0.97647059,  0.99215686],\n",
       "         [ 0.45882353,  0.4509804 ,  0.44313726, ...,  0.98039216,\n",
       "           0.97647059,  0.99215686],\n",
       "         ..., \n",
       "         [ 0.28627452,  0.27843139,  0.27450982, ...,  0.47843137,\n",
       "           0.47058824,  0.4627451 ],\n",
       "         [ 0.28627452,  0.27843139,  0.27450982, ...,  0.47843137,\n",
       "           0.47058824,  0.45490196],\n",
       "         [ 0.28627452,  0.27843139,  0.27843139, ...,  0.47843137,\n",
       "           0.47058824,  0.4509804 ]],\n",
       "\n",
       "        [[ 0.45490196,  0.44705883,  0.41960785, ...,  0.96862745,\n",
       "           0.98431373,  0.99215686],\n",
       "         [ 0.44313726,  0.43529412,  0.42352942, ...,  0.96862745,\n",
       "           0.98431373,  0.99215686],\n",
       "         [ 0.43137255,  0.42352942,  0.42352942, ...,  0.97647059,\n",
       "           0.98039216,  0.99215686],\n",
       "         ..., \n",
       "         [ 0.24705882,  0.23529412,  0.23529412, ...,  0.44705883,\n",
       "           0.43529412,  0.42352942],\n",
       "         [ 0.24313726,  0.23529412,  0.23529412, ...,  0.44705883,\n",
       "           0.43529412,  0.41960785],\n",
       "         [ 0.24313726,  0.23529412,  0.23921569, ...,  0.44705883,\n",
       "           0.43529412,  0.41960785]],\n",
       "\n",
       "        [[ 0.49411765,  0.48627451,  0.45882353, ...,  0.98823529,\n",
       "           1.        ,  0.99215686],\n",
       "         [ 0.48235294,  0.47450981,  0.45882353, ...,  0.98431373,\n",
       "           1.        ,  0.99215686],\n",
       "         [ 0.46666667,  0.4627451 ,  0.45882353, ...,  0.99215686,\n",
       "           1.        ,  0.99215686],\n",
       "         ..., \n",
       "         [ 0.27058825,  0.26666668,  0.25882354, ...,  0.41960785,\n",
       "           0.40000001,  0.39215687],\n",
       "         [ 0.27450982,  0.26666668,  0.25882354, ...,  0.41960785,\n",
       "           0.40000001,  0.38431373],\n",
       "         [ 0.27450982,  0.26666668,  0.26274511, ...,  0.41960785,\n",
       "           0.39607844,  0.38039216]]]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "引入Data Augmentation可以防止对原始数据的过拟合，更generalize model。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3434/3434 [==============================] - 1525s - loss: 1.1879 - acc: 0.6252 - val_loss: 0.0937 - val_acc: 0.9939\n",
      "Epoch 2/10\n",
      "3434/3434 [==============================] - 1524s - loss: 0.9270 - acc: 0.6928 - val_loss: 0.1777 - val_acc: 0.9455\n",
      "Epoch 3/10\n",
      "3434/3434 [==============================] - 4647s - loss: 0.8288 - acc: 0.7368 - val_loss: 0.2506 - val_acc: 0.9455\n",
      "Epoch 4/10\n",
      "3434/3434 [==============================] - 2833s - loss: 0.7535 - acc: 0.7519 - val_loss: 0.1974 - val_acc: 0.9394\n",
      "Epoch 5/10\n",
      "3434/3434 [==============================] - 2792s - loss: 0.7133 - acc: 0.7627 - val_loss: 0.1120 - val_acc: 0.9667\n"
     ]
    }
   ],
   "source": [
    "# data augmentation:\n",
    "sgd = SGD(lr=1e-3, decay=1e-5, momentum=0.9, nesterov=False)\n",
    "\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=3, verbose=0)\n",
    "        ]\n",
    "\n",
    "# prepare data augmentation configuration\n",
    "datagen = ImageDataGenerator(\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(train_data)\n",
    "\n",
    "nb_epoch = 10\n",
    "model.fit_generator(datagen.flow(train_data, train_labels, batch_size=32),\n",
    "                            samples_per_epoch=train_data.shape[0],\n",
    "                            nb_epoch=nb_epoch,\n",
    "                            validation_data=(validation_data, validation_labels),\n",
    "                            callbacks=callbacks, \n",
    "                    )\n",
    "\n",
    "\n",
    "model.save_weights('classification/local-fine-tune-model_da_forth10epoch.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
